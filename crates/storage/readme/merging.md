# Merging Deep-Dive

Complete guide to how conflict resolution works in Calimero Storage.

---

## The Question

**"When does merge actually happen?"**

Most conflicts are resolved by DAG + element IDs (99%). Explicit merge only happens for rare root-level concurrent modifications (1%).

---

## Conflict Resolution Layers

### Layer 1: DAG + Element IDs (95% coverage)

**Handles:** Different keys in collections

```
Node A: map.insert("file-1", data)
         ↓
        Element ID: hash(map_id + "file-1") = elem_123

Node B: map.insert("file-2", data)
         ↓
        Element ID: hash(map_id + "file-2") = elem_456

Sync: elem_123 ≠ elem_456 → No conflict! Both applied.
```

**Performance:** O(1)  
**Code:** Zero  

---

### Layer 2: HLC + LWW (4% coverage)

**Handles:** Same element, clear temporal ordering

```
Node A: map.insert("file-1", v1) @ T1
Node B: map.insert("file-1", v2) @ T2  (T2 > T1)

Sync: Same elem_123, T2 > T1 → Use v2 (LWW)
```

**Performance:** O(1) timestamp comparison  
**Code:** Zero  

---

### Layer 3: Mergeable Trait (1% coverage)

**Handles:** Root-level concurrent modifications

```
Node A: app.owner = "Bob" @ T1       // Modifies root
Node B: app.counter = 42 @ T1        // Modifies root (concurrent!)

Sync: Same root ID, concurrent timestamps
     → Deserialize both states
     → Call MyApp::merge()
     → Merge field-by-field
     → Both updates preserved!
```

**Performance:** O(F×E)  
**Code:** Auto-generated by macro  

---

## When Each Layer Activates

### Test: Different Map Keys

```rust
// Setup
let mut map = Map::new();

// Node A
map.insert("alice", data_a)?;  // elem_1

// Node B
map.insert("bob", data_b)?;    // elem_2

// Sync
// Layer 1 (DAG): elem_1 ≠ elem_2 → Both applied ✅
// Layer 2: Not checked
// Layer 3: Not called
```

**Result:** Both entries present  
**Time:** O(1)  

---

### Test: Same Key, Sequential

```rust
// Setup
let mut map = Map::new();

// Node A @ T1
map.insert("alice", data_v1)?;  // elem_1 @ T1

// Sync happens...

// Node B @ T2 (after sync)
map.insert("alice", data_v2)?;  // elem_1 @ T2

// Sync
// Layer 1 (DAG): Same elem_1
// Layer 2 (HLC): T2 > T1 → Use v2 ✅
// Layer 3: Not called
```

**Result:** v2 wins (latest)  
**Time:** O(1)  

---

### Test: Same Key, Concurrent

```rust
// Setup
let mut map = Map::new();

// Both nodes start with empty map

// Node A @ T1
map.insert("alice", data_v1)?;  // elem_1 @ T1

// Node B @ T1 (concurrent, before seeing A's update)
map.insert("alice", data_v2)?;  // elem_1 @ T1

// Sync
// Layer 1 (DAG): Same elem_1
// Layer 2 (HLC): T1 == T1 → Tie-break by node_id ✅
// Layer 3: Not called
```

**Result:** Higher node_id wins (deterministic)  
**Time:** O(1)  

---

### Test: Root Concurrent Modification

```rust
// Setup
#[app::state]
pub struct MyApp {
    owner: String,
    counter: u64,
}

// Both nodes start with: { owner: "Alice", counter: 5 }

// Node A @ T1
app.owner = "Bob";  // Root modified

// Node B @ T1 (concurrent)
app.counter = 10;   // Root modified

// Sync
// Layer 1 (DAG): Same root ID
// Layer 2 (HLC): T1 == T1, need to merge
// Layer 3 (Mergeable): 
//   if MyApp implements Mergeable:
//     owner = "Bob" or "Alice" (one chosen via LWW)
//     counter = 10 (chosen via LWW)
//   else:
//     Entire state LWW → One update lost ❌
```

**With proper CRDTs at root:**
```rust
#[app::state]
pub struct MyApp {
    owner: LwwRegister<String>,
    counter: Counter,
}

// Merge:
owner.merge(&other.owner)?;    // Timestamp wins
counter.merge(&other.counter)?;  // Sums

// Result: Both updates preserved! ✅
```

**Time:** O(2) = O(1) for this example  

---

## Merge Frequency Analysis

### Production Workload (1000 users)

**Operations/second:**
- 10,000 local writes (typing, clicking)
- 100 remote syncs received
- 1 merge every 10 seconds (rare root conflict)

**Time spent:**
- Local writes: 10ms total (0.001ms each)
- Remote syncs: 2ms total (0.02ms each)
- Merges: 2ms per merge (rare)
- **Network:** 100-500ms per sync

**Bottleneck:** Network (99.9% of time)

### Merge Trigger Scenarios

**High merge frequency (bad):**
- Many root-level non-CRDT fields
- Frequent root modifications
- **Fix:** Use CRDT types at root (LwwRegister, Counter)

**Low merge frequency (good):**
- Mostly element-level modifications
- Clear temporal ordering
- **This is normal:** < 1% of operations

---

## Debugging Merge Issues

### Check: Is Merge Being Called Too Often?

```rust
// Add logging
impl Mergeable for MyApp {
    fn merge(&mut self, other: &Self) -> Result<(), MergeError> {
        eprintln!("⚠️ MERGE CALLED - should be rare!");
        // ... merge logic
    }
}
```

**If you see this frequently:** Your app structure needs improvement.

### Check: Are Root Fields CRDTs?

```rust
// ❌ Bad: Non-CRDT at root
#[app::state]
pub struct MyApp {
    owner: String,  // ← Triggers merge on every owner change!
}

// ✅ Good: CRDT at root
#[app::state]
pub struct MyApp {
    owner: LwwRegister<String>,  // ← Proper timestamps
}
```

### Check: Divergence Logs

```bash
grep "DIVERGENCE DETECTED" logs/*.log
```

**If found:** Something is wrong with merge logic  
**If not found:** System working correctly! ✅

---

## Merge Complexity Analysis

### Simple App

```rust
#[app::state]
pub struct SimpleApp {
    counter: Counter,           // F=1
    metadata: Map<String, String>,  // F=2, E=~10 entries
}

// Merge cost:
// Field 1: O(1) - Counter.merge() sums
// Field 2: O(10) - Map iterates 10 entries
// Total: O(11) ≈ O(1) for small maps
```

### Complex App

```rust
#[app::state]
pub struct ComplexApp {
    documents: Map<String, Document>,  // F=1, E=100 docs
}

pub struct Document {
    content: RGA,                      // Sub-field 1
    metadata: Map<String, String>,     // Sub-field 2, E=5
}

// Merge cost:
// documents.merge():
//   - Iterate 100 entries
//   - For each entry:
//     - content.merge() = O(C) chars
//     - metadata.merge() = O(5) entries
//   - Total: O(100 × (C + 5))
// 
// Typical: C=1000 chars
// Total: O(100,500) operations
// Time: ~5-10ms
// Network: ~100ms
// Merge overhead: ~5-10% of sync time (acceptable!)
```

---

## Best Practices for Fast Merge

### 1. Use Element-Level Sync

```rust
// ✅ Good: Modify element
let mut doc = app.documents.get(&doc_id)?.unwrap();
doc.content.insert_str(pos, text)?;
app.documents.insert(doc_id, doc)?;

// What syncs: Just the RGA element (O(1))
// Merge: Not called at root level!
```

### 2. Batch Root Modifications

```rust
// ⚠️ Multiple root updates
app.field1 = x;  // Generates delta 1
app.field2 = y;  // Generates delta 2
app.field3 = z;  // Generates delta 3
// Each could trigger merge if concurrent

// ✅ Better: Single transaction
app.update_batch(|app| {
    app.field1 = x;
    app.field2 = y;
    app.field3 = z;
});  // Generates one delta
```

### 3. Keep Root Structure Simple

```rust
// ✅ Good: Few root fields
#[app::state]
pub struct MyApp {
    documents: Map<...>,  // Everything under one map
}

// ⚠️ Slower: Many root fields
#[app::state]
pub struct MyApp {
    field1: ...,
    field2: ...,
    // ... 50 fields
}
// Merge iterates all 50 fields!
```

---

## Merge Guarantees

### Mathematical Properties

**Commutativity:** `A.merge(B) == B.merge(A)`

**Associativity:** `(A.merge(B)).merge(C) == A.merge(B.merge(C))`

**Idempotence:** `A.merge(A) == A`

**Convergence:** All nodes that see same updates reach same state

### What This Means

```rust
// Three nodes with different update orders:
Node A sees: [update1, update2, update3]
Node B sees: [update2, update1, update3]
Node C sees: [update3, update1, update2]

// After merge:
final_A == final_B == final_C ✅

// This is the CRDT guarantee!
```

---

## Common Misconceptions

### "Merge is slow so CRDTs are slow"

**Reality:** Merge is called rarely (< 1% of operations)

### "I need to optimize merge"

**Reality:** Network is the bottleneck, not merge

### "CRDTs use more storage"

**Reality:** Element metadata is ~100 bytes. For 1000 elements = 100KB (tiny!)

### "Nested CRDTs cause divergence"

**Reality:** With proper Mergeable implementation, they guarantee convergence!

---

## Summary

**Most conflicts (99%):** Handled automatically by DAG + HLC  
**Rare conflicts (1%):** Handled by Mergeable trait  
**Developer code:** Zero (macro generates everything)  
**Performance:** Negligible overhead (network-bound)  
**Correctness:** Mathematical guarantees (CRDTs converge)  

**Use CRDTs with confidence! The system is designed to be fast and correct.**

---

## Quick Reference: When Is Merge Called?

### ❌ NOT Called (DAG Handles It - 99% of operations)

```rust
// Different map keys
files.insert("file-1", record_A)  // Element ID: 123
files.insert("file-2", record_B)  // Element ID: 456
// → DAG sees different IDs → Mergeable NOT called ✅

// Same key, sequential
files.insert("file-1", v1)  // Timestamp: T1
files.insert("file-1", v2)  // Timestamp: T2 (later)
// → HLC ordering: T2 > T1 → LWW → Mergeable NOT called ✅
```

### ✅ Called (Rare Root Conflicts - 1% of operations)

```rust
// Root concurrent modifications
Node A: app.owner = "Bob"     // Modifies root @ T1
Node B: app.counter = 42       // Modifies root @ T1 (concurrent!)

// → Both modify root
// → Sync detects concurrent root update
// → Mergeable IS called ✅
```

---

## See Also

- [Architecture](architecture.md) - System design
- [Performance](performance.md) - Benchmarks and tips
- [Collections API](collections.md) - Per-collection merge behavior
