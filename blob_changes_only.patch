From b8a2f46c8ece78273b10692374b55b418490d7ac Mon Sep 17 00:00:00 2001
From: alenmestrov <alenmestrov@gmail.com>
Date: Fri, 4 Jul 2025 11:30:54 +0200
Subject: [PATCH 1/7] feat: Blob API runtime host functions

---
 crates/runtime/Cargo.toml           |  5 ++
 crates/runtime/examples/demo.rs     |  9 ++-
 crates/runtime/examples/fetch.rs    |  1 +
 crates/runtime/examples/rps.rs      | 30 ++++++++-
 crates/runtime/src/errors.rs        | 18 ++++++
 crates/runtime/src/lib.rs           |  4 +-
 crates/runtime/src/logic.rs         | 99 ++++++++++++++++++++++++++++-
 crates/runtime/src/logic/imports.rs |  8 ++-
 8 files changed, 165 insertions(+), 9 deletions(-)

diff --git a/crates/runtime/Cargo.toml b/crates/runtime/Cargo.toml
index 90efdf8e..246ca338 100644
--- a/crates/runtime/Cargo.toml
+++ b/crates/runtime/Cargo.toml
@@ -9,16 +9,21 @@ license.workspace = true
 [dependencies]
 borsh = { workspace = true, features = ["derive"] }
 fragile.workspace = true
+futures-util = { workspace = true, features = ["io"] }
+hex.workspace = true
 ouroboros.workspace = true
 owo-colors = { workspace = true, optional = true }
 rand.workspace = true
 serde = { workspace = true, features = ["derive"] }
 thiserror.workspace = true
+tracing.workspace = true
 ureq.workspace = true
 wasmer.workspace = true
 wasmer-types.workspace = true
+tokio = { workspace = true, features = ["rt"] }
 
 calimero-primitives.workspace = true
+calimero-node-primitives.workspace = true
 
 [[example]]
 name = "demo"
diff --git a/crates/runtime/examples/demo.rs b/crates/runtime/examples/demo.rs
index c822515f..29969272 100644
--- a/crates/runtime/examples/demo.rs
+++ b/crates/runtime/examples/demo.rs
@@ -73,7 +73,14 @@ fn main() -> EyreResult<()> {
             .transpose()?
             .unwrap_or_default();
 
-        let outcome = module.run([0; 32].into(), [0; 32].into(), &name, &input, &mut storage)?;
+        let outcome = module.run(
+            [0; 32].into(),
+            [0; 32].into(),
+            &name,
+            &input,
+            &mut storage,
+            None,
+        )?;
 
         // dbg!(&outcome);
 
diff --git a/crates/runtime/examples/fetch.rs b/crates/runtime/examples/fetch.rs
index 0fb7a402..ee1353b9 100644
--- a/crates/runtime/examples/fetch.rs
+++ b/crates/runtime/examples/fetch.rs
@@ -42,6 +42,7 @@ fn main() -> EyreResult<()> {
         "view_account",
         &input,
         &mut storage,
+        None,
     )?;
 
     let returns = String::from_utf8(outcome.returns.unwrap().unwrap()).unwrap();
diff --git a/crates/runtime/examples/rps.rs b/crates/runtime/examples/rps.rs
index b6e60f05..d456fedb 100644
--- a/crates/runtime/examples/rps.rs
+++ b/crates/runtime/examples/rps.rs
@@ -86,6 +86,7 @@ fn main() -> EyreResult<()> {
         "create_keypair",
         &input,
         &mut storage,
+        None,
     )?;
     dbg!(&create_keypair_outcome);
 
@@ -113,6 +114,7 @@ fn main() -> EyreResult<()> {
         "create_keypair",
         &input,
         &mut storage,
+        None,
     )?;
     dbg!(&create_keypair_outcome);
 
@@ -133,7 +135,14 @@ fn main() -> EyreResult<()> {
         "public_key": joe_keypair.pk,
     }))?;
 
-    let join_outcome = module.run([0; 32].into(), [0; 32].into(), "join", &input, &mut storage)?;
+    let join_outcome = module.run(
+        [0; 32].into(),
+        [0; 32].into(),
+        "join",
+        &input,
+        &mut storage,
+        None,
+    )?;
     dbg!(&join_outcome);
 
     let joe_idx =
@@ -150,7 +159,14 @@ fn main() -> EyreResult<()> {
         "public_key": melissa_keypair.pk,
     }))?;
 
-    let join_outcome = module.run([0; 32].into(), [0; 32].into(), "join", &input, &mut storage)?;
+    let join_outcome = module.run(
+        [0; 32].into(),
+        [0; 32].into(),
+        "join",
+        &input,
+        &mut storage,
+        None,
+    )?;
     dbg!(&join_outcome);
 
     let melissa_idx =
@@ -171,6 +187,7 @@ fn main() -> EyreResult<()> {
         "state",
         &input,
         &mut storage,
+        None,
     )?;
     dbg!(&state_outcome);
 
@@ -199,6 +216,7 @@ fn main() -> EyreResult<()> {
         "prepare",
         &input,
         &mut storage,
+        None,
     )?;
     dbg!(&prepare_outcome);
 
@@ -227,6 +245,7 @@ fn main() -> EyreResult<()> {
         "prepare",
         &input,
         &mut storage,
+        None,
     )?;
     dbg!(&prepare_outcome);
 
@@ -252,6 +271,7 @@ fn main() -> EyreResult<()> {
         "commit",
         &input,
         &mut storage,
+        None,
     )?;
     dbg!(&commit_outcome);
 
@@ -273,6 +293,7 @@ fn main() -> EyreResult<()> {
         "commit",
         &input,
         &mut storage,
+        None,
     )?;
     dbg!(&commit_outcome);
 
@@ -293,6 +314,7 @@ fn main() -> EyreResult<()> {
         "reveal",
         &input,
         &mut storage,
+        None,
     )?;
     dbg!(&reveal_outcome);
 
@@ -313,6 +335,7 @@ fn main() -> EyreResult<()> {
         "reveal",
         &input,
         &mut storage,
+        None,
     )?;
     dbg!(&reveal_outcome);
 
@@ -331,6 +354,7 @@ fn main() -> EyreResult<()> {
         "state",
         &input,
         &mut storage,
+        None,
     )?;
     dbg!(&state_outcome);
 
@@ -362,6 +386,7 @@ fn main() -> EyreResult<()> {
         "reset",
         &input,
         &mut storage,
+        None,
     )?;
     dbg!(&reset_outcome);
 
@@ -373,6 +398,7 @@ fn main() -> EyreResult<()> {
         "state",
         &input,
         &mut storage,
+        None,
     )?;
     dbg!(&state_outcome);
 
diff --git a/crates/runtime/src/errors.rs b/crates/runtime/src/errors.rs
index 17161fd9..47a403d8 100644
--- a/crates/runtime/src/errors.rs
+++ b/crates/runtime/src/errors.rs
@@ -102,6 +102,24 @@ pub enum HostError {
     EventKindSizeOverflow,
     #[error("event data size overflow")]
     EventDataSizeOverflow,
+    #[error("blob operations not supported (NodeClient not available)")]
+    BlobsNotSupported,
+    #[error("invalid blob handle")]
+    InvalidBlobHandle,
+    #[error("too many blob handles (max: {max})")]
+    TooManyBlobHandles { max: u64 },
+    #[error("blob buffer too large (size: {size}, max: {max})")]
+    BlobBufferTooLarge { size: u64, max: u64 },
+    #[error("total blob memory exceeded (current: {current}, max: {max})")]
+    TotalBlobMemoryExceeded { current: u64, max: u64 },
+    #[error("blob write too large (size: {size}, max: {max})")]
+    BlobWriteTooLarge { size: u64, max: u64 },
+    #[error("context does not have permission to access this blob handle")]
+    BlobContextMismatch,
+    #[error("too many blob handles open")]
+    BlobHandleLimitExceeded,
+    #[error("total blob memory usage exceeds limit")]
+    BlobMemoryLimitExceeded,
 }
 
 #[derive(Copy, Clone, Debug, Serialize)]
diff --git a/crates/runtime/src/lib.rs b/crates/runtime/src/lib.rs
index 1777d00e..97ee0e7a 100644
--- a/crates/runtime/src/lib.rs
+++ b/crates/runtime/src/lib.rs
@@ -1,3 +1,4 @@
+use calimero_node_primitives::client::NodeClient;
 use calimero_primitives::context::ContextId;
 use calimero_primitives::identity::PublicKey;
 use wasmer::{CompileError, DeserializeError, Instance, NativeEngineExt, SerializeError, Store};
@@ -91,10 +92,11 @@ impl Module {
         method: &str,
         input: &[u8],
         storage: &mut dyn Storage,
+        node_client: Option<NodeClient>,
     ) -> RuntimeResult<Outcome> {
         let context = VMContext::new(input.into(), *context, *executor);
 
-        let mut logic = VMLogic::new(storage, context, &self.limits);
+        let mut logic = VMLogic::new(storage, context, &self.limits, node_client);
 
         let mut store = Store::new(self.engine.clone());
 
diff --git a/crates/runtime/src/logic.rs b/crates/runtime/src/logic.rs
index acc30bff..d1765575 100644
--- a/crates/runtime/src/logic.rs
+++ b/crates/runtime/src/logic.rs
@@ -9,6 +9,7 @@ use std::time::{SystemTime, UNIX_EPOCH};
 use std::vec;
 
 use borsh::from_slice as from_borsh_slice;
+use calimero_node_primitives::client::NodeClient;
 use ouroboros::self_referencing;
 use rand::RngCore;
 use serde::Serialize;
@@ -50,7 +51,7 @@ impl<'a> VMContext<'a> {
     }
 }
 
-#[derive(Debug, Copy, Clone)]
+#[derive(Debug, Clone)]
 pub struct VMLimits {
     pub max_memory_pages: u32,
     pub max_stack_size: usize,
@@ -94,7 +95,10 @@ impl Default for VMLimits {
     }
 }
 
-#[expect(missing_debug_implementations, reason = "storage can't impl Debug")]
+#[expect(
+    missing_debug_implementations,
+    reason = "storage and node_client can't impl Debug"
+)]
 pub struct VMLogic<'a> {
     storage: &'a mut dyn Storage,
     memory: Option<wasmer::Memory>,
@@ -108,10 +112,18 @@ pub struct VMLogic<'a> {
     artifact: Vec<u8>,
     proposals: BTreeMap<[u8; 32], Vec<u8>>,
     approvals: Vec<[u8; 32]>,
+
+    // Blob functionality - just keep the node client
+    node_client: Option<NodeClient>,
 }
 
 impl<'a> VMLogic<'a> {
-    pub fn new(storage: &'a mut dyn Storage, context: VMContext<'a>, limits: &'a VMLimits) -> Self {
+    pub fn new(
+        storage: &'a mut dyn Storage,
+        context: VMContext<'a>,
+        limits: &'a VMLimits,
+        node_client: Option<NodeClient>,
+    ) -> Self {
         VMLogic {
             storage,
             memory: None,
@@ -125,6 +137,9 @@ impl<'a> VMLogic<'a> {
             artifact: vec![],
             proposals: BTreeMap::new(),
             approvals: vec![],
+
+            // Blob functionality
+            node_client,
         }
     }
 
@@ -611,4 +626,82 @@ impl VMHostFunctions<'_> {
 
         Ok(())
     }
+
+    // ========== SIMPLIFIED BLOB HOST FUNCTIONS ==========
+
+    /// Store blob data and return the blob ID in a register
+    /// Returns: 1 if successful, 0 if failed
+    pub fn store_blob(
+        &mut self,
+        data_ptr: u64,
+        data_len: u64,
+        register_id: u64,
+    ) -> VMLogicResult<u32> {
+        // Check if blob functionality is available
+        let node_client = match &self.borrow_logic().node_client {
+            Some(client) => client.clone(),
+            None => return Err(VMLogicError::HostError(HostError::BlobsNotSupported)),
+        };
+
+        let data = self.read_guest_memory(data_ptr, data_len)?;
+
+        // Use the existing add_blob method
+        let blob_id = tokio::task::block_in_place(|| {
+            tokio::runtime::Handle::current().block_on(async {
+                let result = node_client.add_blob(&data[..], None, None).await;
+                result.map(|(blob_id, _size)| blob_id)
+            })
+        })
+        .map_err(|_| VMLogicError::HostError(HostError::BlobsNotSupported))?;
+
+        // Store the blob ID in the register
+        self.with_logic_mut(|logic| {
+            logic
+                .registers
+                .set(logic.limits, register_id, blob_id.as_ref().to_vec())
+        })?;
+
+        Ok(1)
+    }
+
+    /// Load blob data by ID into a register
+    /// Returns: 1 if blob was found and loaded, 0 if not found
+    pub fn load_blob(
+        &mut self,
+        blob_id_ptr: u64,
+        blob_id_len: u64,
+        register_id: u64,
+    ) -> VMLogicResult<u32> {
+        // Check if blob functionality is available
+        let node_client = match &self.borrow_logic().node_client {
+            Some(client) => client.clone(),
+            None => return Err(VMLogicError::HostError(HostError::BlobsNotSupported)),
+        };
+
+        if blob_id_len != 32 {
+            return Err(HostError::InvalidMemoryAccess.into());
+        }
+
+        let blob_id_bytes = self.read_guest_memory_sized::<32>(blob_id_ptr, blob_id_len)?;
+        let blob_id = calimero_primitives::blobs::BlobId::from(blob_id_bytes);
+
+        // Use the existing get_blob_bytes method
+        let blob_data_opt = tokio::task::block_in_place(|| {
+            tokio::runtime::Handle::current()
+                .block_on(async { node_client.get_blob_bytes(&blob_id).await })
+        })
+        .map_err(|_| VMLogicError::HostError(HostError::BlobsNotSupported))?;
+
+        // If blob exists, store it in the register
+        if let Some(blob_data) = blob_data_opt {
+            self.with_logic_mut(|logic| {
+                logic
+                    .registers
+                    .set(logic.limits, register_id, blob_data.to_vec())
+            })?;
+            Ok(1)
+        } else {
+            Ok(0)
+        }
+    }
 }
diff --git a/crates/runtime/src/logic/imports.rs b/crates/runtime/src/logic/imports.rs
index 30e41a06..0f60e74f 100644
--- a/crates/runtime/src/logic/imports.rs
+++ b/crates/runtime/src/logic/imports.rs
@@ -13,7 +13,7 @@ thread_local! {
     static HOST_CTX: AtomicBool = const { AtomicBool::new(false) };
 }
 
-impl VMLogic<'_> {
+impl<'a> VMLogic<'a> {
     #[expect(clippy::too_many_arguments, reason = "Acceptable here")]
     pub fn imports(&mut self, store: &mut Store) -> Imports {
         imports! {
@@ -63,7 +63,7 @@ impl VMLogic<'_> {
                 headers_len: u64,
                 body_ptr: u64,
                 body_len: u64,
-                register_id: u64
+                register_id: u64,
             ) -> u32;
 
             fn random_bytes(ptr: u64, len: u64);
@@ -71,6 +71,10 @@ impl VMLogic<'_> {
 
             fn send_proposal(actions_ptr: u64, actions_len: u64, id_ptr: u64, id_len: u64);
             fn approve_proposal(approval_ptr: u64, approval_len: u64);
+
+            // Simplified blob functions
+            fn store_blob(data_ptr: u64, data_len: u64, register_id: u64) -> u32;
+            fn load_blob(blob_id_ptr: u64, blob_id_len: u64, register_id: u64) -> u32;
         }
     }
 }
-- 
2.39.3 (Apple Git-145)


From ddd40876b247ef10b77b963525fc1255a05d9ba6 Mon Sep 17 00:00:00 2001
From: alenmestrov <alenmestrov@gmail.com>
Date: Fri, 4 Jul 2025 11:56:48 +0200
Subject: [PATCH 2/7] fix: Update context handlers for new runtime method
 signature

---
 crates/context/Cargo.toml                     |  1 +
 crates/context/src/handlers/create_context.rs |  1 +
 crates/context/src/handlers/execute.rs        | 31 ++++++++++++++++---
 3 files changed, 28 insertions(+), 5 deletions(-)

diff --git a/crates/context/Cargo.toml b/crates/context/Cargo.toml
index a89b9c7c..04b85c71 100644
--- a/crates/context/Cargo.toml
+++ b/crates/context/Cargo.toml
@@ -16,6 +16,7 @@ memchr.workspace = true
 ouroboros.workspace = true
 rand.workspace = true
 serde.workspace = true
+serde_json.workspace = true
 tokio = { workspace = true, features = ["sync", "macros"] }
 tracing.workspace = true
 
diff --git a/crates/context/src/handlers/create_context.rs b/crates/context/src/handlers/create_context.rs
index d2710a82..827f6b89 100644
--- a/crates/context/src/handlers/create_context.rs
+++ b/crates/context/src/handlers/create_context.rs
@@ -260,6 +260,7 @@ async fn create_context(
         "init".into(),
         init_params.into(),
         storage,
+        node_client.clone(),
     )
     .await?;
 
diff --git a/crates/context/src/handlers/execute.rs b/crates/context/src/handlers/execute.rs
index 6f38c8de..04d33692 100644
--- a/crates/context/src/handlers/execute.rs
+++ b/crates/context/src/handlers/execute.rs
@@ -367,7 +367,16 @@ async fn internal_execute(
 ) -> eyre::Result<Outcome> {
     let storage = ContextStorage::from(datastore, context.id);
 
-    let (outcome, storage) = execute(guard, module, executor, method, input, storage).await?;
+    let (outcome, storage) = execute(
+        guard,
+        module,
+        executor,
+        method,
+        input,
+        storage,
+        node_client.clone(),
+    )
+    .await?;
 
     if outcome.returns.is_err() {
         return Ok(outcome);
@@ -433,17 +442,29 @@ pub async fn execute(
     method: Cow<'static, str>,
     input: Cow<'static, [u8]>,
     mut storage: ContextStorage,
+    node_client: NodeClient,
 ) -> eyre::Result<(Outcome, ContextStorage)> {
     let context_id = **context;
 
-    global_runtime()
+    // Run WASM execution in blocking context
+    let (outcome, storage) = global_runtime()
         .spawn_blocking(move || {
-            let outcome = module.run(context_id, executor, &method, &input, &mut storage)?;
+            // Run the module - blob operations will be handled on-demand via actor messages
+            let outcome = module.run(
+                context_id,
+                executor,
+                &method,
+                &input,
+                &mut storage,
+                Some(node_client),
+            )?;
 
-            Ok((outcome, storage))
+            Ok::<(Outcome, ContextStorage), eyre::Error>((outcome, storage))
         })
         .await
-        .wrap_err("failed to receive execution response")?
+        .wrap_err("failed to receive execution response")??;
+
+    Ok((outcome, storage))
 }
 
 fn substitute_aliases_in_payload(
-- 
2.39.3 (Apple Git-145)


From d00c0773b4d157c6febbfa4b4246dab461f52bc2 Mon Sep 17 00:00:00 2001
From: alenmestrov <alenmestrov@gmail.com>
Date: Tue, 8 Jul 2025 17:22:21 +0200
Subject: [PATCH 3/7] feat: introduce chunked blob API with blobstore
 integration for large file handling

---
 crates/runtime/Cargo.toml           |   1 +
 crates/runtime/src/logic.rs         | 293 +++++++++++++++++++++++-----
 crates/runtime/src/logic/imports.rs |   9 +-
 3 files changed, 256 insertions(+), 47 deletions(-)

diff --git a/crates/runtime/Cargo.toml b/crates/runtime/Cargo.toml
index 246ca338..007a75d2 100644
--- a/crates/runtime/Cargo.toml
+++ b/crates/runtime/Cargo.toml
@@ -15,6 +15,7 @@ ouroboros.workspace = true
 owo-colors = { workspace = true, optional = true }
 rand.workspace = true
 serde = { workspace = true, features = ["derive"] }
+sha2.workspace = true
 thiserror.workspace = true
 tracing.workspace = true
 ureq.workspace = true
diff --git a/crates/runtime/src/logic.rs b/crates/runtime/src/logic.rs
index d1765575..1d7f48bf 100644
--- a/crates/runtime/src/logic.rs
+++ b/crates/runtime/src/logic.rs
@@ -9,11 +9,15 @@ use std::time::{SystemTime, UNIX_EPOCH};
 use std::vec;
 
 use borsh::from_slice as from_borsh_slice;
+use calimero_primitives::blobs::BlobId;
+
 use calimero_node_primitives::client::NodeClient;
+use futures_util::StreamExt;
 use ouroboros::self_referencing;
 use rand::RngCore;
 use serde::Serialize;
 
+
 use crate::constraint::{Constrained, MaxU64};
 use crate::errors::{FunctionCallError, HostError, Location, PanicContext};
 use crate::store::Storage;
@@ -67,6 +71,10 @@ pub struct VMLimits {
     pub max_event_data_size: u64,
     pub max_storage_key_size: NonZeroU64,
     pub max_storage_value_size: NonZeroU64,
+    // Blob-related limits
+    pub max_blob_handles: u64,
+    pub max_blob_chunk_size: u64,
+    pub max_blob_memory_usage: u64,
     // pub max_execution_time: u64,
     // number of functions per contract
 }
@@ -91,10 +99,33 @@ impl Default for VMLimits {
             max_event_data_size: 16 << 10,                           // 16 KiB
             max_storage_key_size: is_valid((1 << 20).try_into()),    // 1 MiB
             max_storage_value_size: is_valid((10 << 20).try_into()), // 10 MiB
+            // Blob-related defaults
+            max_blob_handles: 100,                                   // 100 concurrent handles
+            max_blob_chunk_size: 64 << 10,                           // 64 KiB chunks
+            max_blob_memory_usage: 100 << 20,                        // 100 MiB total memory
         }
     }
 }
 
+// Blob descriptor management structures
+#[derive(Debug)]
+enum BlobHandle {
+    Write(BlobWriteHandle),
+    Read(BlobReadHandle),
+}
+
+#[derive(Debug)]
+struct BlobWriteHandle {
+    chunk_blob_ids: Vec<BlobId>,                        // IDs of stored chunks
+}
+
+#[derive(Debug)]
+struct BlobReadHandle {
+    blob_id: BlobId,
+}
+
+
+
 #[expect(
     missing_debug_implementations,
     reason = "storage and node_client can't impl Debug"
@@ -113,8 +144,11 @@ pub struct VMLogic<'a> {
     proposals: BTreeMap<[u8; 32], Vec<u8>>,
     approvals: Vec<[u8; 32]>,
 
-    // Blob functionality - just keep the node client
+    // Blob functionality
     node_client: Option<NodeClient>,
+    blob_handles: BTreeMap<u64, BlobHandle>,
+    next_blob_fd: u64,
+    total_blob_memory: u64,
 }
 
 impl<'a> VMLogic<'a> {
@@ -140,6 +174,9 @@ impl<'a> VMLogic<'a> {
 
             // Blob functionality
             node_client,
+            blob_handles: BTreeMap::new(),
+            next_blob_fd: 1, // Start from 1, 0 is reserved for "invalid"
+            total_blob_memory: 0,
         }
     }
 
@@ -627,81 +664,249 @@ impl VMHostFunctions<'_> {
         Ok(())
     }
 
-    // ========== SIMPLIFIED BLOB HOST FUNCTIONS ==========
+    // ========== CHUNKED BLOB HOST FUNCTIONS ==========
 
-    /// Store blob data and return the blob ID in a register
-    /// Returns: 1 if successful, 0 if failed
-    pub fn store_blob(
-        &mut self,
-        data_ptr: u64,
-        data_len: u64,
-        register_id: u64,
-    ) -> VMLogicResult<u32> {
+    /// Create a new blob for writing
+    /// Returns: file descriptor (u64) for writing operations
+    pub fn blob_create(&mut self) -> VMLogicResult<u64> {
+        // Check if blob functionality is available
+        if self.borrow_logic().node_client.is_none() {
+            return Err(VMLogicError::HostError(HostError::BlobsNotSupported));
+        }
+
+        // Check blob handle limits
+        if self.borrow_logic().blob_handles.len() >= self.borrow_logic().limits.max_blob_handles as usize {
+            return Err(VMLogicError::HostError(HostError::TooManyBlobHandles { 
+                max: self.borrow_logic().limits.max_blob_handles 
+            }));
+        }
+
+        let fd = self.with_logic_mut(|logic| {
+            let fd = logic.next_blob_fd;
+            logic.next_blob_fd += 1;
+
+            let handle = BlobHandle::Write(BlobWriteHandle {
+                chunk_blob_ids: Vec::new(),
+            });
+
+            logic.blob_handles.insert(fd, handle);
+            fd
+        });
+
+        Ok(fd)
+    }
+
+    /// Write a chunk of data to a blob
+    /// Returns: number of bytes written (u64)
+    pub fn blob_write(&mut self, fd: u64, data_ptr: u64, data_len: u64) -> VMLogicResult<u64> {
         // Check if blob functionality is available
         let node_client = match &self.borrow_logic().node_client {
             Some(client) => client.clone(),
             None => return Err(VMLogicError::HostError(HostError::BlobsNotSupported)),
         };
 
+        // Validate chunk size
+        if data_len > self.borrow_logic().limits.max_blob_chunk_size {
+            return Err(VMLogicError::HostError(HostError::BlobWriteTooLarge { 
+                size: data_len, 
+                max: self.borrow_logic().limits.max_blob_chunk_size 
+            }));
+        }
+
         let data = self.read_guest_memory(data_ptr, data_len)?;
 
-        // Use the existing add_blob method
-        let blob_id = tokio::task::block_in_place(|| {
+        // Validate handle type once upfront
+        self.with_logic_mut(|logic| {
+            let handle = logic.blob_handles.get(&fd)
+                .ok_or(VMLogicError::HostError(HostError::InvalidBlobHandle))?;
+
+            match handle {
+                BlobHandle::Write(_) => Ok(()),
+                BlobHandle::Read(_) => Err(VMLogicError::HostError(HostError::InvalidBlobHandle)),
+            }
+        })?;
+
+        // Store the app's chunk immediately - whatever size it is
+        let chunk_blob_id = tokio::task::block_in_place(|| {
             tokio::runtime::Handle::current().block_on(async {
-                let result = node_client.add_blob(&data[..], None, None).await;
+                let result = node_client.add_blob(&data[..], Some(data.len() as u64), None).await;
                 result.map(|(blob_id, _size)| blob_id)
             })
         })
         .map_err(|_| VMLogicError::HostError(HostError::BlobsNotSupported))?;
 
-        // Store the blob ID in the register
+        // Store the chunk blob ID reference
         self.with_logic_mut(|logic| {
-            logic
-                .registers
-                .set(logic.limits, register_id, blob_id.as_ref().to_vec())
-        })?;
+            let handle = logic.blob_handles.get_mut(&fd).unwrap(); // We already validated it exists
+            match handle {
+                BlobHandle::Write(w) => {
+                    w.chunk_blob_ids.push(chunk_blob_id);
+                },
+                _ => unreachable!(),
+            }
+        });
 
-        Ok(1)
+        Ok(data.len() as u64)
     }
 
-    /// Load blob data by ID into a register
-    /// Returns: 1 if blob was found and loaded, 0 if not found
-    pub fn load_blob(
-        &mut self,
-        blob_id_ptr: u64,
-        blob_id_len: u64,
-        register_id: u64,
-    ) -> VMLogicResult<u32> {
+        /// Close a blob handle (write or read)
+    /// For write handles: finalizes blob and writes blob_id to memory at blob_id_ptr
+    /// For read handles: just cleanup, blob_id_ptr is ignored
+    /// Returns: 1 if successful, 0 if failed
+    pub fn blob_close(&mut self, fd: u64, blob_id_ptr: u64) -> VMLogicResult<u32> {
         // Check if blob functionality is available
         let node_client = match &self.borrow_logic().node_client {
             Some(client) => client.clone(),
             None => return Err(VMLogicError::HostError(HostError::BlobsNotSupported)),
         };
 
+        // Remove the handle and check its type
+        let handle = self.with_logic_mut(|logic| {
+            logic.blob_handles.remove(&fd)
+                .ok_or(VMLogicError::HostError(HostError::InvalidBlobHandle))
+        })?;
+
+        match handle {
+            BlobHandle::Write(write_handle) => {
+                let blob_id = if write_handle.chunk_blob_ids.is_empty() {
+                    // Empty blob - store directly
+                    tokio::task::block_in_place(|| {
+                        tokio::runtime::Handle::current().block_on(async {
+                            let result = node_client.add_blob(&[][..], Some(0), None).await;
+                            result.map(|(blob_id, _size)| blob_id)
+                        })
+                    })
+                    .map_err(|_| VMLogicError::HostError(HostError::BlobsNotSupported))?
+                } else if write_handle.chunk_blob_ids.len() == 1 {
+                    // Single chunk - return the chunk blob_id directly
+                    write_handle.chunk_blob_ids[0]
+                } else {
+                    // Multiple chunks - create simple linking blob
+                    let mut metadata = Vec::new();
+                    metadata.extend_from_slice(&(write_handle.chunk_blob_ids.len() as u32).to_le_bytes());
+                    
+                    for chunk_id in &write_handle.chunk_blob_ids {
+                        metadata.extend_from_slice(chunk_id.as_ref());
+                    }
+
+                    tokio::task::block_in_place(|| {
+                        tokio::runtime::Handle::current().block_on(async {
+                            let result = node_client.add_blob(&metadata[..], Some(metadata.len() as u64), None).await;
+                            result.map(|(blob_id, _size)| blob_id)
+                        })
+                    })
+                    .map_err(|_| VMLogicError::HostError(HostError::BlobsNotSupported))?
+                };
+
+                // Write the blob ID directly to memory (32 bytes)
+                self.borrow_memory().write(blob_id_ptr, blob_id.as_ref())?;
+
+                Ok(1)
+            },
+            BlobHandle::Read(read_handle) => {
+                // Write the blob ID to memory (32 bytes) - read handles should return their blob_id
+                self.borrow_memory().write(blob_id_ptr, read_handle.blob_id.as_ref())?;
+                Ok(1)
+            }
+        }
+    }
+
+    /// Open a blob for reading
+    /// Returns: file descriptor (u64) for reading operations  
+    pub fn blob_open(&mut self, blob_id_ptr: u64, blob_id_len: u64) -> VMLogicResult<u64> {
+        // Check if blob functionality is available
+        if self.borrow_logic().node_client.is_none() {
+            return Err(VMLogicError::HostError(HostError::BlobsNotSupported));
+        }
+
+        // Check blob handle limits
+        if self.borrow_logic().blob_handles.len() >= self.borrow_logic().limits.max_blob_handles as usize {
+            return Err(VMLogicError::HostError(HostError::TooManyBlobHandles { 
+                max: self.borrow_logic().limits.max_blob_handles 
+            }));
+        }
+
         if blob_id_len != 32 {
             return Err(HostError::InvalidMemoryAccess.into());
         }
 
         let blob_id_bytes = self.read_guest_memory_sized::<32>(blob_id_ptr, blob_id_len)?;
-        let blob_id = calimero_primitives::blobs::BlobId::from(blob_id_bytes);
+        let blob_id = BlobId::from(blob_id_bytes);
 
-        // Use the existing get_blob_bytes method
-        let blob_data_opt = tokio::task::block_in_place(|| {
-            tokio::runtime::Handle::current()
-                .block_on(async { node_client.get_blob_bytes(&blob_id).await })
-        })
-        .map_err(|_| VMLogicError::HostError(HostError::BlobsNotSupported))?;
+        let fd = self.with_logic_mut(|logic| {
+            let fd = logic.next_blob_fd;
+            logic.next_blob_fd += 1;
 
-        // If blob exists, store it in the register
-        if let Some(blob_data) = blob_data_opt {
-            self.with_logic_mut(|logic| {
-                logic
-                    .registers
-                    .set(logic.limits, register_id, blob_data.to_vec())
-            })?;
-            Ok(1)
-        } else {
-            Ok(0)
+            let handle = BlobHandle::Read(BlobReadHandle {
+                blob_id,
+            });
+
+            logic.blob_handles.insert(fd, handle);
+            fd
+        });
+
+        Ok(fd)
+    }
+
+    /// Read a chunk of data from a blob
+    /// Returns: number of bytes read (u64)
+    pub fn blob_read(&mut self, fd: u64, data_ptr: u64, data_len: u64) -> VMLogicResult<u64> {
+        // Check if blob functionality is available
+        let node_client = match &self.borrow_logic().node_client {
+            Some(client) => client.clone(),
+            None => return Err(VMLogicError::HostError(HostError::BlobsNotSupported)),
+        };
+
+        // Validate buffer size
+        if data_len > self.borrow_logic().limits.max_blob_chunk_size {
+            return Err(VMLogicError::HostError(HostError::BlobBufferTooLarge { 
+                size: data_len, 
+                max: self.borrow_logic().limits.max_blob_chunk_size 
+            }));
         }
+
+        // Get blob_id and validate handle once upfront
+        let blob_id = self.with_logic_mut(|logic| {
+            let handle = logic.blob_handles.get(&fd)
+                .ok_or(VMLogicError::HostError(HostError::InvalidBlobHandle))?;
+
+            match handle {
+                BlobHandle::Read(r) => Ok(r.blob_id),
+                BlobHandle::Write(_) => Err(VMLogicError::HostError(HostError::InvalidBlobHandle)),
+            }
+        })?;
+
+        // Stream blob data directly - just get next chunk
+        let blob_data = tokio::task::block_in_place(|| {
+            tokio::runtime::Handle::current().block_on(async {
+                // Get the blob stream using the proper blobstore API
+                let blob_stream = node_client.get_blob(&blob_id)
+                    .map_err(|_| VMLogicError::HostError(HostError::BlobsNotSupported))?;
+
+                let Some(mut blob_stream) = blob_stream else {
+                    return Ok::<Vec<u8>, VMLogicError>(Vec::new()); // Blob not found, return empty
+                };
+
+                // Just get the next chunk from the stream
+                if let Some(chunk_result) = blob_stream.next().await {
+                    let chunk = chunk_result.map_err(|_| VMLogicError::HostError(HostError::BlobsNotSupported))?;
+                    Ok(chunk.to_vec())
+                } else {
+                    Ok(Vec::new()) // End of stream
+                }
+            })
+        })?;
+
+        // Determine how much to copy (limited by requested length)
+        let to_read = std::cmp::min(data_len as usize, blob_data.len());
+        
+        // Copy data to guest memory
+        if to_read > 0 {
+            self.borrow_memory().write(data_ptr, &blob_data[..to_read])?;
+        }
+
+        Ok(to_read as u64)
     }
+
+
 }
diff --git a/crates/runtime/src/logic/imports.rs b/crates/runtime/src/logic/imports.rs
index 0f60e74f..23a2db23 100644
--- a/crates/runtime/src/logic/imports.rs
+++ b/crates/runtime/src/logic/imports.rs
@@ -72,9 +72,12 @@ impl<'a> VMLogic<'a> {
             fn send_proposal(actions_ptr: u64, actions_len: u64, id_ptr: u64, id_len: u64);
             fn approve_proposal(approval_ptr: u64, approval_len: u64);
 
-            // Simplified blob functions
-            fn store_blob(data_ptr: u64, data_len: u64, register_id: u64) -> u32;
-            fn load_blob(blob_id_ptr: u64, blob_id_len: u64, register_id: u64) -> u32;
+            // Chunked blob functions
+            fn blob_create() -> u64;
+            fn blob_write(fd: u64, data_ptr: u64, data_len: u64) -> u64;
+            fn blob_close(fd: u64, blob_id_ptr: u64) -> u32;
+            fn blob_open(blob_id_ptr: u64, blob_id_len: u64) -> u64;
+            fn blob_read(fd: u64, data_ptr: u64, data_len: u64) -> u64;
         }
     }
 }
-- 
2.39.3 (Apple Git-145)


From 3b8c728182c2452ec653285848325f26b589e52a Mon Sep 17 00:00:00 2001
From: alenmestrov <alenmestrov@gmail.com>
Date: Wed, 9 Jul 2025 19:13:12 +0200
Subject: [PATCH 4/7] fix: streaming

---
 crates/runtime/Cargo.toml           |   3 +
 crates/runtime/src/logic.rs         | 188 +++++++++++++---------------
 crates/runtime/src/logic/imports.rs |   2 +-
 3 files changed, 90 insertions(+), 103 deletions(-)

diff --git a/crates/runtime/Cargo.toml b/crates/runtime/Cargo.toml
index 007a75d2..40bf4bbe 100644
--- a/crates/runtime/Cargo.toml
+++ b/crates/runtime/Cargo.toml
@@ -8,6 +8,8 @@ license.workspace = true
 
 [dependencies]
 borsh = { workspace = true, features = ["derive"] }
+bytes.workspace = true
+eyre.workspace = true
 fragile.workspace = true
 futures-util = { workspace = true, features = ["io"] }
 hex.workspace = true
@@ -22,6 +24,7 @@ ureq.workspace = true
 wasmer.workspace = true
 wasmer-types.workspace = true
 tokio = { workspace = true, features = ["rt"] }
+tokio-stream.workspace = true
 
 calimero-primitives.workspace = true
 calimero-node-primitives.workspace = true
diff --git a/crates/runtime/src/logic.rs b/crates/runtime/src/logic.rs
index 1d7f48bf..fe2cee72 100644
--- a/crates/runtime/src/logic.rs
+++ b/crates/runtime/src/logic.rs
@@ -4,18 +4,19 @@
 use core::fmt;
 use core::num::NonZeroU64;
 use std::borrow::Cow;
-use std::collections::BTreeMap;
+use std::collections::{BTreeMap, HashMap};
 use std::time::{SystemTime, UNIX_EPOCH};
 use std::vec;
 
 use borsh::from_slice as from_borsh_slice;
-use calimero_primitives::blobs::BlobId;
-
 use calimero_node_primitives::client::NodeClient;
-use futures_util::StreamExt;
+use calimero_primitives::blobs::BlobId;
+use futures_util::{StreamExt, TryStreamExt};
 use ouroboros::self_referencing;
 use rand::RngCore;
 use serde::Serialize;
+use tokio::sync::mpsc;
+use tokio_stream::wrappers::UnboundedReceiverStream;
 
 
 use crate::constraint::{Constrained, MaxU64};
@@ -55,7 +56,7 @@ impl<'a> VMContext<'a> {
     }
 }
 
-#[derive(Debug, Clone)]
+#[derive(Debug, Clone, Copy)]
 pub struct VMLimits {
     pub max_memory_pages: u32,
     pub max_stack_size: usize,
@@ -71,10 +72,9 @@ pub struct VMLimits {
     pub max_event_data_size: u64,
     pub max_storage_key_size: NonZeroU64,
     pub max_storage_value_size: NonZeroU64,
-    // Blob-related limits
+    // Blob limits
     pub max_blob_handles: u64,
     pub max_blob_chunk_size: u64,
-    pub max_blob_memory_usage: u64,
     // pub max_execution_time: u64,
     // number of functions per contract
 }
@@ -99,10 +99,8 @@ impl Default for VMLimits {
             max_event_data_size: 16 << 10,                           // 16 KiB
             max_storage_key_size: is_valid((1 << 20).try_into()),    // 1 MiB
             max_storage_value_size: is_valid((10 << 20).try_into()), // 10 MiB
-            // Blob-related defaults
-            max_blob_handles: 100,                                   // 100 concurrent handles
-            max_blob_chunk_size: 64 << 10,                           // 64 KiB chunks
-            max_blob_memory_usage: 100 << 20,                        // 100 MiB total memory
+            max_blob_handles: 100,                                   // Max blob handles
+            max_blob_chunk_size: 10 << 20,                          // 10 MiB max chunk size
         }
     }
 }
@@ -116,7 +114,8 @@ enum BlobHandle {
 
 #[derive(Debug)]
 struct BlobWriteHandle {
-    chunk_blob_ids: Vec<BlobId>,                        // IDs of stored chunks
+    sender: mpsc::UnboundedSender<Vec<u8>>,
+    completion_handle: tokio::task::JoinHandle<eyre::Result<(BlobId, u64)>>,
 }
 
 #[derive(Debug)]
@@ -124,8 +123,6 @@ struct BlobReadHandle {
     blob_id: BlobId,
 }
 
-
-
 #[expect(
     missing_debug_implementations,
     reason = "storage and node_client can't impl Debug"
@@ -146,9 +143,8 @@ pub struct VMLogic<'a> {
 
     // Blob functionality
     node_client: Option<NodeClient>,
-    blob_handles: BTreeMap<u64, BlobHandle>,
+    blob_handles: HashMap<u64, BlobHandle>,
     next_blob_fd: u64,
-    total_blob_memory: u64,
 }
 
 impl<'a> VMLogic<'a> {
@@ -174,9 +170,8 @@ impl<'a> VMLogic<'a> {
 
             // Blob functionality
             node_client,
-            blob_handles: BTreeMap::new(),
-            next_blob_fd: 1, // Start from 1, 0 is reserved for "invalid"
-            total_blob_memory: 0,
+            blob_handles: HashMap::new(),
+            next_blob_fd: 1,
         }
     }
 
@@ -669,15 +664,15 @@ impl VMHostFunctions<'_> {
     /// Create a new blob for writing
     /// Returns: file descriptor (u64) for writing operations
     pub fn blob_create(&mut self) -> VMLogicResult<u64> {
-        // Check if blob functionality is available
         if self.borrow_logic().node_client.is_none() {
             return Err(VMLogicError::HostError(HostError::BlobsNotSupported));
         }
 
-        // Check blob handle limits
-        if self.borrow_logic().blob_handles.len() >= self.borrow_logic().limits.max_blob_handles as usize {
-            return Err(VMLogicError::HostError(HostError::TooManyBlobHandles { 
-                max: self.borrow_logic().limits.max_blob_handles 
+        if self.borrow_logic().blob_handles.len()
+            >= self.borrow_logic().limits.max_blob_handles as usize
+        {
+            return Err(VMLogicError::HostError(HostError::TooManyBlobHandles {
+                max: self.borrow_logic().limits.max_blob_handles,
             }));
         }
 
@@ -685,11 +680,26 @@ impl VMHostFunctions<'_> {
             let fd = logic.next_blob_fd;
             logic.next_blob_fd += 1;
 
+            let (data_sender, data_receiver) = mpsc::unbounded_channel();
+
+            let node_client = logic.node_client.clone().unwrap();
+
+            let completion_handle = tokio::spawn(async move {
+                let stream = UnboundedReceiverStream::new(data_receiver);
+
+                let byte_stream =
+                    stream.map(|data: Vec<u8>| Ok::<bytes::Bytes, std::io::Error>(data.into()));
+                let reader = byte_stream.into_async_read();
+
+                node_client.add_blob(reader, None, None).await
+            });
+
             let handle = BlobHandle::Write(BlobWriteHandle {
-                chunk_blob_ids: Vec::new(),
+                sender: data_sender,
+                completion_handle,
             });
 
-            logic.blob_handles.insert(fd, handle);
+            drop(logic.blob_handles.insert(fd, handle));
             fd
         });
 
@@ -699,11 +709,9 @@ impl VMHostFunctions<'_> {
     /// Write a chunk of data to a blob
     /// Returns: number of bytes written (u64)
     pub fn blob_write(&mut self, fd: u64, data_ptr: u64, data_len: u64) -> VMLogicResult<u64> {
-        // Check if blob functionality is available
-        let node_client = match &self.borrow_logic().node_client {
-            Some(client) => client.clone(),
-            None => return Err(VMLogicError::HostError(HostError::BlobsNotSupported)),
-        };
+        if self.borrow_logic().node_client.is_none() {
+            return Err(VMLogicError::HostError(HostError::BlobsNotSupported));
+        }
 
         // Validate chunk size
         if data_len > self.borrow_logic().limits.max_blob_chunk_size {
@@ -715,9 +723,10 @@ impl VMHostFunctions<'_> {
 
         let data = self.read_guest_memory(data_ptr, data_len)?;
 
-        // Validate handle type once upfront
         self.with_logic_mut(|logic| {
-            let handle = logic.blob_handles.get(&fd)
+            let handle = logic
+                .blob_handles
+                .get(&fd)
                 .ok_or(VMLogicError::HostError(HostError::InvalidBlobHandle))?;
 
             match handle {
@@ -726,103 +735,79 @@ impl VMHostFunctions<'_> {
             }
         })?;
 
-        // Store the app's chunk immediately - whatever size it is
-        let chunk_blob_id = tokio::task::block_in_place(|| {
-            tokio::runtime::Handle::current().block_on(async {
-                let result = node_client.add_blob(&data[..], Some(data.len() as u64), None).await;
-                result.map(|(blob_id, _size)| blob_id)
-            })
-        })
-        .map_err(|_| VMLogicError::HostError(HostError::BlobsNotSupported))?;
-
-        // Store the chunk blob ID reference
+        let data_len = data.len() as u64;
         self.with_logic_mut(|logic| {
             let handle = logic.blob_handles.get_mut(&fd).unwrap(); // We already validated it exists
             match handle {
                 BlobHandle::Write(w) => {
-                    w.chunk_blob_ids.push(chunk_blob_id);
-                },
+                    w.sender
+                        .send(data.clone())
+                        .map_err(|_| VMLogicError::HostError(HostError::InvalidBlobHandle))?;
+                }
                 _ => unreachable!(),
             }
-        });
+            Ok::<(), VMLogicError>(())
+        })?;
 
-        Ok(data.len() as u64)
+        Ok(data_len)
     }
 
-        /// Close a blob handle (write or read)
-    /// For write handles: finalizes blob and writes blob_id to memory at blob_id_ptr
-    /// For read handles: just cleanup, blob_id_ptr is ignored
-    /// Returns: 1 if successful, 0 if failed
-    pub fn blob_close(&mut self, fd: u64, blob_id_ptr: u64) -> VMLogicResult<u32> {
-        // Check if blob functionality is available
-        let node_client = match &self.borrow_logic().node_client {
-            Some(client) => client.clone(),
-            None => return Err(VMLogicError::HostError(HostError::BlobsNotSupported)),
-        };
+    /// Close a blob handle and get the resulting blob ID
+    /// Returns: 1 on success
+    pub fn blob_close(
+        &mut self,
+        fd: u64,
+        blob_id_ptr: u64,
+        blob_id_len: u64,
+    ) -> VMLogicResult<u32> {
+        if self.borrow_logic().node_client.is_none() {
+            return Err(VMLogicError::HostError(HostError::BlobsNotSupported));
+        }
+
+        if blob_id_len != 32 {
+            return Err(HostError::InvalidMemoryAccess.into());
+        }
 
-        // Remove the handle and check its type
         let handle = self.with_logic_mut(|logic| {
-            logic.blob_handles.remove(&fd)
+            logic
+                .blob_handles
+                .remove(&fd)
                 .ok_or(VMLogicError::HostError(HostError::InvalidBlobHandle))
         })?;
 
         match handle {
             BlobHandle::Write(write_handle) => {
-                let blob_id = if write_handle.chunk_blob_ids.is_empty() {
-                    // Empty blob - store directly
-                    tokio::task::block_in_place(|| {
-                        tokio::runtime::Handle::current().block_on(async {
-                            let result = node_client.add_blob(&[][..], Some(0), None).await;
-                            result.map(|(blob_id, _size)| blob_id)
-                        })
-                    })
-                    .map_err(|_| VMLogicError::HostError(HostError::BlobsNotSupported))?
-                } else if write_handle.chunk_blob_ids.len() == 1 {
-                    // Single chunk - return the chunk blob_id directly
-                    write_handle.chunk_blob_ids[0]
-                } else {
-                    // Multiple chunks - create simple linking blob
-                    let mut metadata = Vec::new();
-                    metadata.extend_from_slice(&(write_handle.chunk_blob_ids.len() as u32).to_le_bytes());
-                    
-                    for chunk_id in &write_handle.chunk_blob_ids {
-                        metadata.extend_from_slice(chunk_id.as_ref());
-                    }
-
-                    tokio::task::block_in_place(|| {
-                        tokio::runtime::Handle::current().block_on(async {
-                            let result = node_client.add_blob(&metadata[..], Some(metadata.len() as u64), None).await;
-                            result.map(|(blob_id, _size)| blob_id)
-                        })
-                    })
-                    .map_err(|_| VMLogicError::HostError(HostError::BlobsNotSupported))?
-                };
+                drop(write_handle.sender);
 
-                // Write the blob ID directly to memory (32 bytes)
-                self.borrow_memory().write(blob_id_ptr, blob_id.as_ref())?;
+                let (blob_id, _size) = tokio::task::block_in_place(|| {
+                    tokio::runtime::Handle::current().block_on(write_handle.completion_handle)
+                })
+                .map_err(|_| VMLogicError::HostError(HostError::BlobsNotSupported))?
+                .map_err(|_| VMLogicError::HostError(HostError::BlobsNotSupported))?;
 
-                Ok(1)
-            },
+                self.borrow_memory().write(blob_id_ptr, blob_id.as_ref())?;
+            }
             BlobHandle::Read(read_handle) => {
-                // Write the blob ID to memory (32 bytes) - read handles should return their blob_id
-                self.borrow_memory().write(blob_id_ptr, read_handle.blob_id.as_ref())?;
-                Ok(1)
+                self.borrow_memory()
+                    .write(blob_id_ptr, read_handle.blob_id.as_ref())?;
             }
         }
+
+        Ok(1)
     }
 
     /// Open a blob for reading
     /// Returns: file descriptor (u64) for reading operations  
     pub fn blob_open(&mut self, blob_id_ptr: u64, blob_id_len: u64) -> VMLogicResult<u64> {
-        // Check if blob functionality is available
         if self.borrow_logic().node_client.is_none() {
             return Err(VMLogicError::HostError(HostError::BlobsNotSupported));
         }
 
-        // Check blob handle limits
-        if self.borrow_logic().blob_handles.len() >= self.borrow_logic().limits.max_blob_handles as usize {
-            return Err(VMLogicError::HostError(HostError::TooManyBlobHandles { 
-                max: self.borrow_logic().limits.max_blob_handles 
+        if self.borrow_logic().blob_handles.len()
+            >= self.borrow_logic().limits.max_blob_handles as usize
+        {
+            return Err(VMLogicError::HostError(HostError::TooManyBlobHandles {
+                max: self.borrow_logic().limits.max_blob_handles,
             }));
         }
 
@@ -840,8 +825,7 @@ impl VMHostFunctions<'_> {
             let handle = BlobHandle::Read(BlobReadHandle {
                 blob_id,
             });
-
-            logic.blob_handles.insert(fd, handle);
+            drop(logic.blob_handles.insert(fd, handle));
             fd
         });
 
diff --git a/crates/runtime/src/logic/imports.rs b/crates/runtime/src/logic/imports.rs
index 23a2db23..a08960c6 100644
--- a/crates/runtime/src/logic/imports.rs
+++ b/crates/runtime/src/logic/imports.rs
@@ -75,7 +75,7 @@ impl<'a> VMLogic<'a> {
             // Chunked blob functions
             fn blob_create() -> u64;
             fn blob_write(fd: u64, data_ptr: u64, data_len: u64) -> u64;
-            fn blob_close(fd: u64, blob_id_ptr: u64) -> u32;
+            fn blob_close(fd: u64, blob_id_ptr: u64, blob_id_len: u64) -> u32;
             fn blob_open(blob_id_ptr: u64, blob_id_len: u64) -> u64;
             fn blob_read(fd: u64, data_ptr: u64, data_len: u64) -> u64;
         }
-- 
2.39.3 (Apple Git-145)


From 4fa108c4778333268b8e6fea71faad15ead7201e Mon Sep 17 00:00:00 2001
From: alenmestrov <alenmestrov@gmail.com>
Date: Wed, 9 Jul 2025 19:53:05 +0200
Subject: [PATCH 5/7] fix: reading functionality

---
 crates/runtime/src/logic.rs | 156 +++++++++++++++++++++++++-----------
 1 file changed, 109 insertions(+), 47 deletions(-)

diff --git a/crates/runtime/src/logic.rs b/crates/runtime/src/logic.rs
index fe2cee72..71b7cc19 100644
--- a/crates/runtime/src/logic.rs
+++ b/crates/runtime/src/logic.rs
@@ -9,6 +9,7 @@ use std::time::{SystemTime, UNIX_EPOCH};
 use std::vec;
 
 use borsh::from_slice as from_borsh_slice;
+use bytes;
 use calimero_node_primitives::client::NodeClient;
 use calimero_primitives::blobs::BlobId;
 use futures_util::{StreamExt, TryStreamExt};
@@ -18,7 +19,6 @@ use serde::Serialize;
 use tokio::sync::mpsc;
 use tokio_stream::wrappers::UnboundedReceiverStream;
 
-
 use crate::constraint::{Constrained, MaxU64};
 use crate::errors::{FunctionCallError, HostError, Location, PanicContext};
 use crate::store::Storage;
@@ -100,13 +100,11 @@ impl Default for VMLimits {
             max_storage_key_size: is_valid((1 << 20).try_into()),    // 1 MiB
             max_storage_value_size: is_valid((10 << 20).try_into()), // 10 MiB
             max_blob_handles: 100,                                   // Max blob handles
-            max_blob_chunk_size: 10 << 20,                          // 10 MiB max chunk size
+            max_blob_chunk_size: 10 << 20,                           // 10 MiB max chunk size
         }
     }
 }
 
-// Blob descriptor management structures
-#[derive(Debug)]
 enum BlobHandle {
     Write(BlobWriteHandle),
     Read(BlobReadHandle),
@@ -118,9 +116,14 @@ struct BlobWriteHandle {
     completion_handle: tokio::task::JoinHandle<eyre::Result<(BlobId, u64)>>,
 }
 
-#[derive(Debug)]
 struct BlobReadHandle {
     blob_id: BlobId,
+    // Stream state
+    stream:
+        Option<Box<dyn futures_util::Stream<Item = Result<bytes::Bytes, std::io::Error>> + Unpin>>,
+    // Buffer for partial chunks
+    partial_chunk: Vec<u8>,
+    position: u64,
 }
 
 #[expect(
@@ -659,7 +662,7 @@ impl VMHostFunctions<'_> {
         Ok(())
     }
 
-    // ========== CHUNKED BLOB HOST FUNCTIONS ==========
+    // ========== BLOB FUNCTIONS ==========
 
     /// Create a new blob for writing
     /// Returns: file descriptor (u64) for writing operations
@@ -715,9 +718,9 @@ impl VMHostFunctions<'_> {
 
         // Validate chunk size
         if data_len > self.borrow_logic().limits.max_blob_chunk_size {
-            return Err(VMLogicError::HostError(HostError::BlobWriteTooLarge { 
-                size: data_len, 
-                max: self.borrow_logic().limits.max_blob_chunk_size 
+            return Err(VMLogicError::HostError(HostError::BlobWriteTooLarge {
+                size: data_len,
+                max: self.borrow_logic().limits.max_blob_chunk_size,
             }));
         }
 
@@ -824,6 +827,9 @@ impl VMHostFunctions<'_> {
 
             let handle = BlobHandle::Read(BlobReadHandle {
                 blob_id,
+                stream: None,
+                partial_chunk: Vec::new(),
+                position: 0,
             });
             drop(logic.blob_handles.insert(fd, handle));
             fd
@@ -833,7 +839,7 @@ impl VMHostFunctions<'_> {
     }
 
     /// Read a chunk of data from a blob
-    /// Returns: number of bytes read (u64)
+    /// Returns: number of bytes read (u64)  
     pub fn blob_read(&mut self, fd: u64, data_ptr: u64, data_len: u64) -> VMLogicResult<u64> {
         // Check if blob functionality is available
         let node_client = match &self.borrow_logic().node_client {
@@ -843,54 +849,110 @@ impl VMHostFunctions<'_> {
 
         // Validate buffer size
         if data_len > self.borrow_logic().limits.max_blob_chunk_size {
-            return Err(VMLogicError::HostError(HostError::BlobBufferTooLarge { 
-                size: data_len, 
-                max: self.borrow_logic().limits.max_blob_chunk_size 
+            return Err(VMLogicError::HostError(HostError::BlobBufferTooLarge {
+                size: data_len,
+                max: self.borrow_logic().limits.max_blob_chunk_size,
             }));
         }
 
-        // Get blob_id and validate handle once upfront
-        let blob_id = self.with_logic_mut(|logic| {
-            let handle = logic.blob_handles.get(&fd)
+        if data_len == 0 {
+            return Ok(0);
+        }
+
+        let mut output_buffer = Vec::with_capacity(data_len as usize);
+
+        let bytes_read = self.with_logic_mut(|logic| -> VMLogicResult<u64> {
+            let handle = logic
+                .blob_handles
+                .get_mut(&fd)
                 .ok_or(VMLogicError::HostError(HostError::InvalidBlobHandle))?;
 
-            match handle {
-                BlobHandle::Read(r) => Ok(r.blob_id),
-                BlobHandle::Write(_) => Err(VMLogicError::HostError(HostError::InvalidBlobHandle)),
+            let read_handle = match handle {
+                BlobHandle::Read(r) => r,
+                BlobHandle::Write(_) => {
+                    return Err(VMLogicError::HostError(HostError::InvalidBlobHandle))
+                }
+            };
+
+            let needed = data_len as usize;
+
+            // First, consume any buffered partial chunk data
+            let from_partial = std::cmp::min(read_handle.partial_chunk.len(), needed);
+            if from_partial > 0 {
+                output_buffer.extend_from_slice(&read_handle.partial_chunk[..from_partial]);
+                drop(read_handle.partial_chunk.drain(..from_partial));
+
+                if output_buffer.len() >= needed {
+                    read_handle.position += output_buffer.len() as u64;
+                    return Ok(output_buffer.len() as u64);
+                }
             }
-        })?;
 
-        // Stream blob data directly - just get next chunk
-        let blob_data = tokio::task::block_in_place(|| {
-            tokio::runtime::Handle::current().block_on(async {
-                // Get the blob stream using the proper blobstore API
-                let blob_stream = node_client.get_blob(&blob_id)
-                    .map_err(|_| VMLogicError::HostError(HostError::BlobsNotSupported))?;
-
-                let Some(mut blob_stream) = blob_stream else {
-                    return Ok::<Vec<u8>, VMLogicError>(Vec::new()); // Blob not found, return empty
-                };
-
-                // Just get the next chunk from the stream
-                if let Some(chunk_result) = blob_stream.next().await {
-                    let chunk = chunk_result.map_err(|_| VMLogicError::HostError(HostError::BlobsNotSupported))?;
-                    Ok(chunk.to_vec())
-                } else {
-                    Ok(Vec::new()) // End of stream
+            if read_handle.stream.is_none() {
+                let blob_stream = tokio::task::block_in_place(|| {
+                    tokio::runtime::Handle::current().block_on(async {
+                        node_client
+                            .get_blob(&read_handle.blob_id)
+                            .map_err(|_| VMLogicError::HostError(HostError::BlobsNotSupported))
+                    })
+                })?;
+
+                match blob_stream {
+                    Some(stream) => {
+                        let mapped_stream = stream.map(|result| match result {
+                            Ok(chunk) => Ok(bytes::Bytes::copy_from_slice(&chunk)),
+                            Err(_) => Err(std::io::Error::new(
+                                std::io::ErrorKind::Other,
+                                "blob read error",
+                            )),
+                        });
+                        read_handle.stream = Some(Box::new(mapped_stream));
+                    }
+                    None => {
+                        read_handle.position += output_buffer.len() as u64;
+                        return Ok(output_buffer.len() as u64);
+                    }
                 }
-            })
+            }
+
+            if let Some(stream) = &mut read_handle.stream {
+                tokio::task::block_in_place(|| {
+                    tokio::runtime::Handle::current().block_on(async {
+                        while output_buffer.len() < needed {
+                            match stream.next().await {
+                                Some(Ok(chunk)) => {
+                                    let chunk_bytes = chunk.as_ref();
+                                    let remaining_needed = needed - output_buffer.len();
+
+                                    if chunk_bytes.len() <= remaining_needed {
+                                        output_buffer.extend_from_slice(chunk_bytes);
+                                    } else {
+                                        output_buffer
+                                            .extend_from_slice(&chunk_bytes[..remaining_needed]);
+                                        read_handle
+                                            .partial_chunk
+                                            .extend_from_slice(&chunk_bytes[remaining_needed..]);
+                                        break;
+                                    }
+                                }
+                                Some(Err(_)) | None => {
+                                    break;
+                                }
+                            }
+                        }
+                        Ok::<(), VMLogicError>(())
+                    })
+                })?;
+            }
+
+            read_handle.position += output_buffer.len() as u64;
+            Ok(output_buffer.len() as u64)
         })?;
 
-        // Determine how much to copy (limited by requested length)
-        let to_read = std::cmp::min(data_len as usize, blob_data.len());
-        
-        // Copy data to guest memory
-        if to_read > 0 {
-            self.borrow_memory().write(data_ptr, &blob_data[..to_read])?;
+        if bytes_read > 0 {
+            self.borrow_memory().write(data_ptr, &output_buffer)?;
         }
 
-        Ok(to_read as u64)
+        Ok(bytes_read)
     }
-
-
 }
-- 
2.39.3 (Apple Git-145)


From bb14ec0959403920fc529ba0ffe104cdd2d1cc69 Mon Sep 17 00:00:00 2001
From: alenmestrov <alenmestrov@gmail.com>
Date: Thu, 10 Jul 2025 09:49:32 +0200
Subject: [PATCH 6/7] feat: implemented Cursor for reading, removed unused deps
 from Cargo.toml

---
 crates/runtime/Cargo.toml   |  7 ++----
 crates/runtime/src/logic.rs | 46 +++++++++++++++++++++++++------------
 2 files changed, 33 insertions(+), 20 deletions(-)

diff --git a/crates/runtime/Cargo.toml b/crates/runtime/Cargo.toml
index 40bf4bbe..c50a82f8 100644
--- a/crates/runtime/Cargo.toml
+++ b/crates/runtime/Cargo.toml
@@ -12,19 +12,16 @@ bytes.workspace = true
 eyre.workspace = true
 fragile.workspace = true
 futures-util = { workspace = true, features = ["io"] }
-hex.workspace = true
 ouroboros.workspace = true
 owo-colors = { workspace = true, optional = true }
 rand.workspace = true
 serde = { workspace = true, features = ["derive"] }
-sha2.workspace = true
 thiserror.workspace = true
-tracing.workspace = true
+tokio = { workspace = true, features = ["rt"] }
+tokio-stream.workspace = true
 ureq.workspace = true
 wasmer.workspace = true
 wasmer-types.workspace = true
-tokio = { workspace = true, features = ["rt"] }
-tokio-stream.workspace = true
 
 calimero-primitives.workspace = true
 calimero-node-primitives.workspace = true
diff --git a/crates/runtime/src/logic.rs b/crates/runtime/src/logic.rs
index 71b7cc19..253f0355 100644
--- a/crates/runtime/src/logic.rs
+++ b/crates/runtime/src/logic.rs
@@ -16,6 +16,7 @@ use futures_util::{StreamExt, TryStreamExt};
 use ouroboros::self_referencing;
 use rand::RngCore;
 use serde::Serialize;
+use std::io::{Cursor, Read};
 use tokio::sync::mpsc;
 use tokio_stream::wrappers::UnboundedReceiverStream;
 
@@ -121,8 +122,8 @@ struct BlobReadHandle {
     // Stream state
     stream:
         Option<Box<dyn futures_util::Stream<Item = Result<bytes::Bytes, std::io::Error>> + Unpin>>,
-    // Buffer for partial chunks
-    partial_chunk: Vec<u8>,
+    // Cursor for current storage chunk - automatic position tracking!
+    current_chunk_cursor: Option<Cursor<Vec<u8>>>,
     position: u64,
 }
 
@@ -828,7 +829,7 @@ impl VMHostFunctions<'_> {
             let handle = BlobHandle::Read(BlobReadHandle {
                 blob_id,
                 stream: None,
-                partial_chunk: Vec::new(),
+                current_chunk_cursor: None,
                 position: 0,
             });
             drop(logic.blob_handles.insert(fd, handle));
@@ -876,15 +877,28 @@ impl VMHostFunctions<'_> {
 
             let needed = data_len as usize;
 
-            // First, consume any buffered partial chunk data
-            let from_partial = std::cmp::min(read_handle.partial_chunk.len(), needed);
-            if from_partial > 0 {
-                output_buffer.extend_from_slice(&read_handle.partial_chunk[..from_partial]);
-                drop(read_handle.partial_chunk.drain(..from_partial));
-
-                if output_buffer.len() >= needed {
-                    read_handle.position += output_buffer.len() as u64;
-                    return Ok(output_buffer.len() as u64);
+            // First, try to read from current chunk cursor if available
+            if let Some(cursor) = &mut read_handle.current_chunk_cursor {
+                let mut temp_buffer = vec![0u8; needed];
+                match cursor.read(&mut temp_buffer) {
+                    Ok(bytes_from_cursor) => {
+                        output_buffer.extend_from_slice(&temp_buffer[..bytes_from_cursor]);
+                        
+                        // If cursor is exhausted, remove it
+                        if bytes_from_cursor == 0 || cursor.position() >= cursor.get_ref().len() as u64 {
+                            read_handle.current_chunk_cursor = None;
+                        }
+                        
+                        // If we satisfied the request entirely from cursor, we're done
+                        if output_buffer.len() >= needed {
+                            read_handle.position += output_buffer.len() as u64;
+                            return Ok(output_buffer.len() as u64);
+                        }
+                    }
+                    Err(_) => {
+                        // Cursor error, remove it
+                        read_handle.current_chunk_cursor = None;
+                    }
                 }
             }
 
@@ -927,11 +941,13 @@ impl VMHostFunctions<'_> {
                                     if chunk_bytes.len() <= remaining_needed {
                                         output_buffer.extend_from_slice(chunk_bytes);
                                     } else {
+                                        // Use part of chunk, save rest in cursor for next time
                                         output_buffer
                                             .extend_from_slice(&chunk_bytes[..remaining_needed]);
-                                        read_handle
-                                            .partial_chunk
-                                            .extend_from_slice(&chunk_bytes[remaining_needed..]);
+                                        
+                                        // Create cursor with remaining data
+                                        let remaining_data = chunk_bytes[remaining_needed..].to_vec();
+                                        read_handle.current_chunk_cursor = Some(Cursor::new(remaining_data));
                                         break;
                                     }
                                 }
-- 
2.39.3 (Apple Git-145)


From c6109489fc92b138132ff7c74aaf2e8f7ba8cff0 Mon Sep 17 00:00:00 2001
From: alenmestrov <alenmestrov@gmail.com>
Date: Thu, 10 Jul 2025 09:49:56 +0200
Subject: [PATCH 7/7] fix: lint

---
 crates/runtime/src/logic.rs | 18 +++++++++++-------
 1 file changed, 11 insertions(+), 7 deletions(-)

diff --git a/crates/runtime/src/logic.rs b/crates/runtime/src/logic.rs
index 253f0355..0551c0aa 100644
--- a/crates/runtime/src/logic.rs
+++ b/crates/runtime/src/logic.rs
@@ -5,6 +5,7 @@ use core::fmt;
 use core::num::NonZeroU64;
 use std::borrow::Cow;
 use std::collections::{BTreeMap, HashMap};
+use std::io::{Cursor, Read};
 use std::time::{SystemTime, UNIX_EPOCH};
 use std::vec;
 
@@ -16,7 +17,6 @@ use futures_util::{StreamExt, TryStreamExt};
 use ouroboros::self_referencing;
 use rand::RngCore;
 use serde::Serialize;
-use std::io::{Cursor, Read};
 use tokio::sync::mpsc;
 use tokio_stream::wrappers::UnboundedReceiverStream;
 
@@ -883,12 +883,14 @@ impl VMHostFunctions<'_> {
                 match cursor.read(&mut temp_buffer) {
                     Ok(bytes_from_cursor) => {
                         output_buffer.extend_from_slice(&temp_buffer[..bytes_from_cursor]);
-                        
+
                         // If cursor is exhausted, remove it
-                        if bytes_from_cursor == 0 || cursor.position() >= cursor.get_ref().len() as u64 {
+                        if bytes_from_cursor == 0
+                            || cursor.position() >= cursor.get_ref().len() as u64
+                        {
                             read_handle.current_chunk_cursor = None;
                         }
-                        
+
                         // If we satisfied the request entirely from cursor, we're done
                         if output_buffer.len() >= needed {
                             read_handle.position += output_buffer.len() as u64;
@@ -944,10 +946,12 @@ impl VMHostFunctions<'_> {
                                         // Use part of chunk, save rest in cursor for next time
                                         output_buffer
                                             .extend_from_slice(&chunk_bytes[..remaining_needed]);
-                                        
+
                                         // Create cursor with remaining data
-                                        let remaining_data = chunk_bytes[remaining_needed..].to_vec();
-                                        read_handle.current_chunk_cursor = Some(Cursor::new(remaining_data));
+                                        let remaining_data =
+                                            chunk_bytes[remaining_needed..].to_vec();
+                                        read_handle.current_chunk_cursor =
+                                            Some(Cursor::new(remaining_data));
                                         break;
                                     }
                                 }
-- 
2.39.3 (Apple Git-145)

